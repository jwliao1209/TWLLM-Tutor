name: twllm_qlora_IT-train_QB_history-valid_QB_history_wo_answer_details

dataset:
  train:
    data_path: data/train_data/QB_social/train_QB_history_9000.json
    max_length: 512
    with_answer_details: False
  valid:
    data_path: data/train_data/QB_social/valid_QB_history_205.json
    max_length: 2048
    with_answer_details: False

dataloader:
  train:
    batch_size: 16
    num_workers: 2
  valid:
    batch_size: 1  # do not change
    num_workers: 1  # do not change

model:
  finetune_type: instruction_tuning
  adapter: qlora
  base_model_path: model_weight/Taiwan-LLM-7B-v2.0-chat
  lora_rank: 8
  lora_alpha: 16
  lora_dropout: 0.1
  nbit: 4

device:
  cuda_id: 0

optim:
  optimizer:
    name: adamw  # adamw, lion
    lr: 0.0002
    weight_decay: 0.00001
  lr_scheduler:
    name: constant  # linear, constant, cosine, cosine_warmup
    warm_up_step: 0

trainer:
  epoch: 10
  accum_grad_step: 1
